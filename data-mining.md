# Data Mining

1. Attribute is a data field, representing the characteristics or features of data object. :heavy_check_mark:

1. Data mining algorithms must be efficient and scalable in order to effectively extract information from huge amounts of data. :heavy_check_mark:

1. A major problem with the mean is its sensitivity to extreme (outlier) values. :heavy_check_mark:

1. Blievability reflects how much the data are trusted by users, while interpretability reflects how easy the data are understood. :heavy_check_mark:

1. clustering means measuring the similarity among a set of attributes to predict similar clusters of a given set of data points. :x:

1. duplicate records requires data normalization :x:

1. incomplete data means that it contains errors and outlier. :heavy_check_mark:

1. in cluster technique, one cluster can hold at most one object. :x:

1. Real world data tend to be dirty, incomplete, and inconsistent. :heavy_check_mark:

1. Good database and data entry procedure design should help maximize the number of missing values or errors. :x:

1. Redundant data occur often when integrating multiple databases. :heavy_check_mark:

1. Dimensionality reduction may help to eliminate irrelevant features or reduce noise. :heavy_check_mark:

---

1. The **range** is the difference between the largest (max) and the smallest (min).

1. The **low** standard deviation means that the data observation tends to be very close to the mean.

1. A data set may contain objects that don not comply with the general behavior or model of the data. These data objects are called **outliers** .

1. **Data Mining** is the process of discovering interesting patterns from massive amounts of data.

1. A **Data warehouse** is a repository for long-term storage of data from multiple sources, organized so as to facilitate management and decision making

1. A **decision tree** is a flowchart-like tree structure, where each node denotes a test on an attribute value, each branch represents an outcome of the test, and tree leaves represent classes or class distributions.

1. Data **cleaning** can be applied to remove noise and correct inconsistencies in data.

1. Data **integration** merges data from multiple sources into a coherent data store such as a data warehouse.

1. Data **reduction** can reduce data size by, for instance, aggregating, eliminating redundant features, or clustering.

1. Data **normalization** may be applied, where data are scaled to fall within a smaller range like 0.0 to 1.0.

1. A **data warehouse** is a repository of information collected from multiple sources, stored under a unified schema, and usually residing at a single site.

1. "Data about data" is referred to as **meta data**.

1. **data reduction** is the process of reducing the number of random variables or attributes under consideration.
