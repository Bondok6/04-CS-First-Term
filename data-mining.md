# Data Mining

1. Attribute is a data field, representing the characteristics or features of data object. :heavy_check_mark:

1. Data mining algorithms must be efficient and scalable in order to effectively extract information from huge amounts of data. :heavy_check_mark:

1. A major problem with the mean is its sensitivity to extreme (outlier) values. :heavy_check_mark:

1. Blievability reflects how much the data are trusted by users, while interpretability reflects how easy the data are understood. :heavy_check_mark:

1. clustering means measuring the similarity among a set of attributes to predict similar clusters of a given set of data points. :x:

1. duplicate records requires data normalization :x:

1. incomplete data means that it contains errors and outlier. :heavy_check_mark:

1. in cluster technique, one cluster can hold at most one object. :x:

1. Real world data tend to be dirty, incomplete, and inconsistent. :heavy_check_mark:

1. Good database and data entry procedure design should help maximize the number of missing values or errors. :x:

1. Redundant data occur often when integrating multiple databases. :heavy_check_mark:

1. Dimensionality reduction may help to eliminate irrelevant features or reduce noise. :heavy_check_mark:

1. Data mining turns a large collection of data into knowledge. :heavy_check_mark:

1. Attribute is a data field, representing the characteristics or features of data object. :heavy_check_mark:

1. Variance and standard deviation are measures of data dispersion. :heavy_check_mark:

1. Data mining algorithms must be efficient and scalable in order to effectively extract information from huge amounts of data :heavy_check_mark:

1. A major problem with the mean is its sensitivity to extreme (e.g., outlier) values. :heavy_check_mark:

1. The Table consists of a set of attributes (rows) and usually stores a large set of tuples columns). :x:

1. In clustering techniques, one cluster can hold at most one object. :x:

1. Dimensionality reduction may help to eliminate irrelevant features. :heavy_check_mark:

1. Feature subset selection is another way to reduce dimensionality :heavy_check_mark:

1. Data visualization aims to communicate data clearly and effectively through graphical representation. :heavy_check_mark:

1. Ensemble methods can be used to increase overall accuracy by learning and combining a series of individual (base) classifier models. :x:

1. The learning and classification steps of decision tree induction are complex and slow. :x:

1. Decision trees and classification rules can be easy to interpret  :heavy_check_mark:

---

1. The **range** is the difference between the largest (max) and the smallest (min).

1. The **low** standard deviation means that the data observation tends to be very close to the mean.

1. A data set may contain objects that don not comply with the general behavior or model of the data. These data objects are called **outliers** .

1. **Data Mining** is the process of discovering interesting patterns from massive amounts of data.

1. A **Data warehouse** is a repository for long-term storage of data from multiple sources, organized so as to facilitate management and decision making

1. A **decision tree** is a flowchart-like tree structure, where each node denotes a test on an attribute value, each branch represents an outcome of the test, and tree leaves represent classes or class distributions.

1. Data **cleaning** can be applied to remove noise and correct inconsistencies in data.

1. Data **integration** merges data from multiple sources into a coherent data store such as a data warehouse.

1. Data **reduction** can reduce data size by, for instance, aggregating, eliminating redundant features, or clustering.

1. Data **normalization** may be applied, where data are scaled to fall within a smaller range like 0.0 to 1.0.

1. A **data warehouse** is a repository of information collected from multiple sources, stored under a unified schema, and usually residing at a single site.

1. "Data about data" is referred to as **meta data**.

1. **Data reduction** is the process of reducing the number of random variables or attributes under consideration.

1. Classification has numerous applications, including **fraud detection, performance prediction, manufacturing, and medical diagnosis**

1. When the class label of each training tuple is _provided_, this type is known as **supervised learning**.

1. In the **learning** step, a classifier model is built describing a predetermined set of data classes or concepts.

1. The **accuracy** of a classifier on a give test set is the percentage of test set tuples that are correctly classified by the classifier.

1. **Scalability** is the ability to construct the classifier efficiently given large amounts of data.

1. An **ordinal** attribute is an attribute with possible values that have a meaningful order or ranking among them.

1. **Binary** attributes are nominal attributes with only two possible states (such as 1 and 9 or true and false).
