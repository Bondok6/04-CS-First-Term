# Image Processing

1. Digitizing image intensity amplitude is called  
   a) sampling  
   **b) quantization**  
   c) framing  
   d) Both A and B

1. Compressed image can be recovered back by  
   a) image enhancement  
   **b) image decompression**  
   c) image contrast  
   d) image equalization

1. Image compression comprised of  
   a) encoder  
   b) decoder  
   c) frames  
   **d) Both A and B**

1. What would you use compression for?  
   **a) Making an image file smaller**  
   b) Modifying an image

1. Makes the file smaller by deleting parts of the file permanently (forever)  
   **a) Lossy Compression**  
   b) Lossless Compression

1. Makes the file smaller by giving repeated patterns/colors a specific code  
   a) Lossy Compression  
   **b) Lossless Compression**

1. Which file types use Lossy compression?  
   **a) JPEG, GIF**  
   b) PNG, BMP

1. Which file types use Lossless compression?  
   a) JPEG, GIF  
   **b) PNG, BMP**

1. Which of these is an advantage for Lossy compression?  
   **a) The file size becomes significantly (much) smaller**  
   b) The file size does not become much smaller than 50%

1. Error of the image is referred to as  
   A. pixels  
   B. matrix  
   C. frames  
   **D. noise**

1. Reducing the data required referred to  
   A. image enhancement  
   **B. image compression**  
   C. image contrast  
   D. image equalization

1. Digitizing the coordinate values is called  
   A. radiance  
   B. illuminance  
   **C. sampling**  
   D. quantization

1. Black and white images have only  
   **A. 2 levels**  
   B. 3 levels  
   C. 4 levels  
   D. 5 levels

1. A continuous image is digitised at ---------- points.  
   a) random  
   b) vertex  
   c) contour  
   d) sampling  
   answer: d  
   Explanation: The samp

1. The transition between continuous values of the image function and its digital equivalent is called ----------  
   a) Quantisation  
   b) Sampling  
   c) Rasterisation  
   d) None of the Mentioned  
   answer: a  
   Explanation: The transition between continuous values of the image function and its digital equivalent is called Quantisation.

1. Images quantised with insufficient brightness levels will lead to the occurrence of ---------  
   a) Pixillation  
   b) Blurring  
   c) False Contours  
   d) None of the Mentioned  
   answer: c  
   Explanation: This effect arises when the number brightness levels is lower that which the human eye can distinguish.

1. The smallest discernible change in intensity level is called ---------  
   a) Intensity Resolution  
   b) Contour  
   c) Saturation  
   d) Contrast  
   answer: a  
   Explanation: Number of bits used to quantise intensity of an image is called intensity resolution.

1. Quantitatively, spatial resolution cannot be represented in which of the following ways  
   a) line pairs  
   b) pixels  
   c) dots  
   d) none of the Mentioned  
   answer: d  
   Explanation: All the options can be used to represent spatial resolution.

1. An image is considered to be a function of a(x,y), where a represents:  
   a) Height of image  
   b) Width of image  
   c) Amplitude of image  
   d) Resolution of image  
   answer: c  
   Explanation: The image is a collection of dots with a definite intensity or amplitude.

1. What is pixel?  
   a) Pixel is the elements of a digital image  
   b) Pixel is the elements of an analog image  
   c) Pixel is the cluster of a digital image  
   d) Pixel is the cluster of an analog image  
   answer: a  
   Explanation: An Image is a collection of individual points referred as pixel, thus a Pixel is the element of a digital image.

1. Which means the assigning meaning to a recognized object.  
   a) Interpretation  
   b) Recognition  
   c) Acquisition  
   d) Segmentation  
   answer: a  
   Explanation: The interpretation is called the assigning meaning to recognized object.

1. What is the first and foremost step in Image Processing?  
   a) Image restoration  
   b) Image enhancement  
   c) Image acquisition  
   d) Segmentation  
   answer: c  
   Explanation: Image acquisition is the first process in image processing. Note that acquisition could be as simple as being given an image that is already in digital form. Generally, the image acquisition stage involves preprocessing, such as scaling.

1. In which step of processing, the images are subdivided successively into smaller regions?  
   a) Image enhancement  
   b) Image acquisition  
   c) Segmentation  
   d) Wavelets  
   answer: d  
   Explanation: Wavelets are the foundation for representing images in various degrees of resolution. Wavelets are particularly used for image data compression and for pyramidal representation, in which images are subdivided successively into smaller regions.

1. What is the next step in image processing after compression?  
   a) Wavelets  
   b) Segmentation  
   c) Representation and description  
   d) Morphological processing  
   answer: d  
   Explanation: Steps in image processing:  
   Image acquisition-> Image enhancement-> Image restoration-> Color image processing-> Wavelets and multi resolution processing-> Compression-> Morphological processing-> Segmentation-> Representation & description-> Object recognition.

1. What is the step that is performed before color image processing in image processing?  
   a) Wavelets and multi resolution processing  
   b) Image enhancement  
   c) Image restoration  
   d) Image acquisition  
   answer: c  
   Explanation: Steps in image processing:  
   Image acquisition-> Image enhancement-> Image restoration-> Color image processing-> Wavelets and multi resolution processing-> Compression-> Morphological processing-> Segmentation-> Representation & description-> Object recognition.

1. How many number of steps are involved in image processing?  
   a) 10  
   b) 9  
   c) 11  
   d) 12  
   answer: a  
   Explanation: Steps in image processing:  
   Image acquisition-> Image enhancement-> Image restoration-> Color image processing-> Wavelets and multi resolution processing-> Compression-> Morphological processing-> Segmentation-> Representation & description-> Object recognition.

1. What is the expanded form of JPEG?  
   a) Joint Photographic Expansion Group  
   b) Joint Photographic Experts Group  
   c) Joint Photographs Expansion Group  
   d) Joint Photographic Expanded Group  
   answer: b  
   Explanation: Image compression is familiar (perhaps inadvertently) to most users of computers in the form of image file extensions, such as the jpg file extension used in the JPEG (Joint Photographic Experts Group) image compression standard.

1. Which of the following step deals with tools for extracting image components those are useful in the representation and description of shape?  
   a) Segmentation  
   b) Representation & description  
   c) Compression  
   d) Morphological processing  
   answer: d  
   Explanation: Morphological processing deals with tools for extracting image components that are useful in the representation and description of shape. The material in this chapter begins a transition from processes that output images to processes that output image attributes.

1. In which step of the processing, assigning a label (e.g., “vehicle”) to an object based on its descriptors is done?  
   a) Object recognition  
   b) Morphological processing  
   c) Segmentation  
   d) Representation & description  
   answer: a  
   Explanation: Recognition is the process that assigns a label (e.g., “vehicle”) to an object based on its descriptors. We conclude our coverage of digital image processing with the development of methods for recognition of individual objects.

1. What role does the segmentation play in image processing?  
   a) Deals with extracting attributes that result in some quantitative information of interest  
   b) Deals with techniques for reducing the storage required saving an image, or the bandwidth required transmitting it  
   c) Deals with partitioning an image into its constituent parts or objects  
   d) Deals with property in which images are subdivided successively into smaller regions  
   answer: c  
   Explanation: Segmentation procedures partition an image into its constituent parts or objects. In general, autonomous segmentation is one of the most difficult tasks in digital image processing. A rugged segmentation procedure brings the process a long way toward successful solution of imaging problems that require objects to be identified individually.

1. What is the correct sequence of steps in image processing?  
   a) Image acquisition->Image enhancement->Image restoration->Color image processing->Compression->Wavelets and multi resolution processing->Morphological processing->Segmentation->Representation & description->Object recognition  
   b) Image acquisition->Image enhancement->Image restoration->Color image processing->Wavelets and multi resolution processing->Compression->Morphological processing->Segmentation->Representation & description->Object recognition  
   c) Image acquisition->Image enhancement->Color image processing->Image restoration->Wavelets and multi resolution processing->Compression->Morphological processing->Segmentation->Representation & description->Object recognition  
   d) Image acquisition->Image enhancement->Image restoration->Color image processing->Wavelets and multi resolution processing->Compression->Morphological processing->Representation & description->Segmentation->Object recognition  
   answer: b  
   Explanation: Steps in image processing:  
   Image acquisition-> Image enhancement->Image restoration->Color image processing->Wavelets and multi resolution processing->Compression->Morphological processing->Segmentation->Representation & description->Object recognition.

1. To convert a continuous sensed data into Digital form, which of the following is required?  
   a) Sampling  
   b) Quantization  
   c) Both Sampling and Quantization  
   d) Neither Sampling nor Quantization  
   answer: c  
   Explanation: The output of the most sensor is a continuous waveform and the amplitude and spatial behavior of such waveform are related to the physical phenomenon being sensed.

1. Assume that an image f(x, y) is sampled so that the result has M rows and N columns. If the values of the coordinates at the origin are (x, y) = (0, 0), then the notation (0,
1. is used to signify :  
    a) Second sample along first row  
    b) First sample along second row  
    c) First sample along first row  
    d) Second sample along second row  
   answer: a  
    Explanation: The values of the coordinates at the origin are (x, y) = (0, 0). Then, the next coordinate values (second sample) along the first row of the image are represented as (x, y) = (0,  
   1..

1. The resulting image of sampling and quantization is considered a matrix of real numbers. By what name(s) the element of this matrix array is called ----------  
   a) Image element or Picture element  
   b) Pixel or Pel  
   c) All of the mentioned  
   d) None of the mentioned  
   answer: c  
   Explanation: Sampling and Quantization of an image f(x, y) forms a matrix of real numbers and each element of this matrix array is commonly known as Image element or Picture element or Pixel or Pel.

1. Validate the statement “When in an Image an appreciable number of pixels exhibit high dynamic range, the image will have high contrast.”  
   a) True  
   b) False  
   answer: a  
   Explanation: In an Image if an appreciable number of pixels exhibit high dynamic range property, the image will have high contrast.

1. A continuous image is digitized at ---------- points.  
   a) random  
   b) vertex  
   c) contour  
   d) sampling  
   answer: d  
   Explanation: The sampling points are ordered in the plane and their relation is called a Grid.

1. The transition between continuous values of the image function and its digital equivalent is called ----------  
   a) Quantization  
   b) Sampling  
   c) Rasterization  
   d) None of the Mentioned  
   answer: a  
   Explanation: The transition between continuous values of the image function and its digital equivalent is called Quantization.

1. The smallest discernible change in intensity level is called ---------  
   a) Intensity Resolution  
   b) Contour  
   c) Saturation  
   d) Contrast  
   answer: a  
   Explanation: Number of bits used to quantize intensity of an image is called intensity resolution.

1. The section of the real plane spanned by the coordinates of an image is called the ----------  
   a) Spacial Domain  
   b) Coordinate Axes  
   c) Plane of Symmetry  
   d) None of the Mentioned  
   answer: a  
   Explanation: The section of the real plane spanned by the coordinates of an image is called the Spacial Domain, with the x and y coordinates referred to as Spacial coordinates.

1. The difference between the highest and the lowest intensity levels in an image is ---------  
   a) Noise  
   b) Saturation  
   c) Contrast  
   d) Brightness  
   answer: c  
   Explanation: Contrast is the measure of the difference is intensity between the highest and the lowest intensity levels in an image.

1. Image processing approaches operating directly on pixels of input image work directly in ----------  
   a) Transform domain  
   b) Spatial domain  
   c) Inverse transformation  
   d) None of the Mentioned  
   answer: b  
   Explanation: Operations directly on pixels of input image work directly in Spatial Domain.

1. Noise reduction is obtained by blurring the image using smoothing filter.  
   a) True  
   b) False  
   answer: a  
   Explanation: Noise reduction is obtained by blurring the image using smoothing filter. Blurring is used in pre-processing steps, such as removal of small details from an image prior to object extraction and, bridging of small gaps in lines or curves.

1. What is the output of a smoothing, linear spatial filter?  
   a) Median of pixels  
   b) Maximum of pixels  
   c) Minimum of pixels  
   d) Average of pixels  
   answer: d  
   Explanation: The output or response of a smoothing, linear spatial filter is simply the average of the pixels contained in the neighbourhood of the filter mask.

1. Smoothing linear filter is also known as median filter.  
   a) True  
   b) False  
   answer: b  
   Explanation: Since the smoothing spatial filter performs the average of the pixels, it is also called as averaging filter.

1. Which of the following in an image can be removed by using smoothing filter?  
   a) Smooth transitions of gray levels  
   b) Smooth transitions of brightness levels  
   c) Sharp transitions of gray levels  
   d) Sharp transitions of brightness levels  
   answer: c  
   Explanation: Smoothing filter replaces the value of every pixel in an image by the average value of the gray levels. So, this helps in removing the sharp transitions in the gray levels between the pixels. This is done because, random noise typically consists of sharp transitions in gray levels.

1. Which of the following is the disadvantage of using smoothing filter?  
   a) Blur edges  
   b) Blur inner pixels  
   c) Remove sharp transitions  
   d) Sharp edges  
   answer: a  
   Explanation: Edges, which almost always are desirable features of an image, also are characterized by sharp transitions in gray level. So, averaging filters have an undesirable side effect that they blur these edges.

1. The mask shown in the figure below belongs to which type of filter?  
   ![img](https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-smoothing-spatial-filters-q7@2x.png)  
    a) Sharpening spatial filter  
    b) Median filter  
    c) Sharpening frequency filter  
    d) Smoothing spatial filter  
   answer: d  
    Explanation: This is a smoothing spatial filter. This mask yields a so called weighted average, which means that different pixels are multiplied with different coefficient values. This helps in giving much importance to the some pixels at the expense of others.

1. The mask shown in the figure below belongs to which type of filter?  
   ![img](https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-smoothing-spatial-filters-q8@2x.png)  
    a) Sharpening spatial filter  
    b) Median filter  
    c) Smoothing spatial filter  
    d) Sharpening frequency filter  
   answer: c  
    Explanation: The mask shown in the figure represents a 3×3 smoothing filter. Use of this filter yields the standard average of the pixels under the mask.

1. If the size of the averaging filter used to smooth the original image to first image is 9, then what would be the size of the averaging filter used in smoothing the same original picture to second in second image?  
   ![img](https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-smoothing-spatial-filters-q10.png)  
    a) 3  
    b) 5  
    c) 9  
    d) 15  
   answer: d  
    Explanation: We know that, as the size of the filter used in smoothening the original image that is averaging filter increases then the blurring of the image. Since the second image is more blurred than the first image, the window size should be more than 9.

1. Median filter belongs to which category of filters?  
   a) Linear spatial filter  
   b) Frequency domain filter  
   c) Order static filter  
   d) Sharpening filter  
   answer: c  
   Explanation: The median filter belongs to order static filters, which, as the name implies, replaces the value of the pixel by the median of the gray levels that are present in the neighbourhood of the pixels.

1. Median filters are effective in the presence of impulse noise.  
   a) True  
   b) False  
   answer: a  
   Explanation: Median filters are used to remove impulse noises, also called as salt-and-pepper noise because of its appearance as white and black dots in the image.

1. In Homomorphic filtering which of the following operations is used to convert input image to discrete Fourier transformed function?  
   a) Logarithmic operation  
   b) Exponential operation  
   c) Negative transformation  
   d) None of the mentioned  
   answer: a  
   Explanation: For an image is expressed as the multiplication of illumination and reflectance component i.e. f(x, y) = i(x, y) \* r(x, y), the equation can’t be used directly to operate separately on the frequency component of illumination and reflectance because the Fourier transform of the product of two function is not separable. So, the logarithmic operation is used.I{z(x,y)}=I{ln⁡(f(x,y)) }=I{ln⁡(i(x,y)) }+I{ln⁡(r(x,y))}.

1. **Convolution in Spatial Domain** Is _Multiplication_ in **Frequency Domain**.

1. Sudden changes in intensity produces peak in  
   a) **first derivative**  
   b) second derivative  
   c) third derivative  
   d) Both A and B

1. Gaussian noise is referred to as  
   a) red noise  
   b) black noise  
   c) white noise  
   d) **normal noise**

1. Digitizing image intensity amplitude is called  
   a) sampling  
   b) **quantization**  
   c) framing  
   d) Both A and B

1. For line detection we use mask that is  
   a) Gaussian  
   b) **laplacian**  
   c) ideal  
   d) butterworth

1. Gradient computation equation is  
   a) **\|Gx\| + \|Gy\|**  
   b) \|Gx\| - \|Gy\|  
   c) \|Gx\| / \|Gy\|  
   d) \|Gx\| x \|Gy\|

1. For finding horizontal lines we use mask of values  
   a) **[-1 -1 -1;
   2 2 2;
   -1 -1 -1]**  
   b) [2 -1 -1;
   -1 2 -1;
   -1 -1 2]  
   c) [-1 2 -1;
   -1 2 -1;
   -1 2 -1]  
   d) [-1 -1 2;
   -1 2 -1;
   2 -1 -1]

1. To avoid negative values taking absolute values in lapacian image doubles **thickness of lines**.

1. Horizontal gradient pixels are denoted by **Gx**

1. Filter that replaces pixel value with medians of intensity levels is **median filter**

1. For finding lines at angle 45 we use mask of values  
   a) [-1 -1 -1; 2 2 2; -1 -1 -1]  
   b) **[2 -1 -1; -1 2 -1; -1 -1 2]**  
   c) [-1 2 -1; -1 2 -1; -1 2 -1]  
   d) [-1 -1 2; -1 2 -1;2 -1 -1]

1. Second derivative approximation says that values along ramp must be  
   a) nonzero  
   b) **zero**  
   c) positive  
   d) negative

1. High pass filters promotes  
   a) low intensity components  
   b) mid intensity components  
   c) **high intensity components**  
   d) all components

1. Gradient magnitude images are more useful in  
   a) point detection  
   b) line detection  
   c) area detection  
   d) **edge detection**

1. Image having gradient pixels is called **gradient image**

1. Digital images are displayed as a discrete set if  
   a) values  
   b) numbers  
   c) frequencies  
   d) **intensities**

1. ----- filter cannot be implemented using convolution mechanism  
   a) average  
   b) **gausian**  
   c) median  
   d) disk

1. To remove salt-and-pepper noise witout blurring we use  
   a) max filter  
   b) **median filter**  
   c) min filter  
   d) smoothing filter

1. Sharpening the images is commonly accomplished by performing a spatial ------- of the image field.  
   a) Min Filter  
   b) Smoothing Filter  
   c) Integration  
   d) **Differentiation**

1. One of the following filters is nonlinear  
   a) Gaussian Filter  
   b) Averaging Filter  
   c) Laplacian Filter  
   d) **Median**

1. the sum of all elements inthe mask of the smoothing averaging spatial filtering must be equal to  
   a) m rows  
   b) n columns  
   c) n\*m  
   d) **1**

1. Edge detection in images is commonly accomplished by performing a spatial ------ of the image field  
   a) Min Filter  
   b) Smoothing Filter  
   c) Integration  
   d) **Differentiation**

1. For finding vertical lines we use mask of values  
   a) [-1 -1 -1; 2 2 2; -1 -1 -1]  
   b) [2 -1 -1; -1 2 -1; -1 -1 2]  
   c) **[-1 2 -1; -1 2 -1; -1 2 -1]**  
   d) [-1 -1 2; -1 2 -1;2 -1 -1]

1. Which of the following expression is used to denote spatial domain process?  
   a) g(x,y)=T[f(x,y)]  
   b) f(x+y)=T[g(x+y)]  
   c) g(xy)=T[f(xy)]  
   d) g(x-y)=T[f(x-y)]  
   answer: a  
   Explanation: Spatial domain processes will be denoted by the expression g(x,y)=T[f(x,y)], where f(x,y) is the input image, g(x,y) is the processed image, and T is an operator on f, defined over some neighborhood of (x, y). In addition, T can operate on a set of input images, such as performing the pixel-by-pixel sum of K images for noise reduction.

1. Which of the following is the primary objective of sharpening of an image?  
   a) Blurring the image  
   b) Highlight fine details in the image  
   c) Increase the brightness of the image  
   d) Decrease the brightness of the image  
   answer: b  
   Explanation: The sharpening of image helps in highlighting the fine details that are present in the image or to enhance the details that are blurred due to some reason like adding noise.

1. Image sharpening process is used in electronic printing.  
   a) True  
   b) False  
   answer: a  
   Explanation: The applications of image sharpening is present in various fields like electronic printing, autonomous guidance in military systems, medical imaging and industrial inspection.

1. In spatial domain, which of the following operation is done on the pixels in sharpening the image?  
   a) Integration  
   b) Average  
   c) Median  
   d) Differentiation  
   answer: d  
   Explanation: We know that, in blurring the image, we perform the average of pixels which can be considered as integration. As sharpening is the opposite process of blurring, logically we can tell that we perform differentiation on the pixels to sharpen the image.

1. Image differentiation enhances the edges, discontinuities and deemphasizes the pixels with slow varying gray levels.  
   a) True  
   b) False  
   answer: a  
   Explanation: Fundamentally, the strength of the response of the derivative operative is proportional to the degree of discontinuity in the image. So, we can state that image differentiation enhances the edges, discontinuities and deemphasizes the pixels with slow varying gray levels.

1. If f(x,y) is an image function of two variables, then the first order derivative of a one dimensional function, f(x) is:  
    a) f(x+1.-f(x)  
    b) f(x)-f(x+1.
   c) f(x-1.-f(x+  
   d) f(x)+f(x- 1.
   answer: a  
   Explanation: The first order derivative of a single dimensional function f(x) is the difference between f(x) and f(x+1..  
   That is, ∂f/∂x=f(x+1.-f(x).

1. Isolated point is also called as noise point.  
   a) True  
   b) False  
   answer: a  
   Explanation: The point which has very high or very low gray level value compared to its neighbours, then that point is called as isolated point or noise point. The noise point of is of one pixel size.

1. What is the thickness of the edges produced by first order derivatives when compared to that of second order derivatives?  
   a) Finer  
   b) Equal  
   c) Thicker  
   d) Independent  
   answer: c  
   Explanation: We know that, the first order derivative is nonzero along the entire ramp while the second order is zero along the ramp. So, we can conclude that the first order derivatives produce thicker edges and the second order derivatives produce much finer edges.

1. First order derivative can enhance the fine detail in the image compared to that of second order derivative.  
   a) True  
   b) False  
   answer: b  
   Explanation: The response at and around the noise point is much stronger for the second order derivative than for the first order derivative. So, we can state that the second order derivative is better to enhance the fine details in the image including noise when compared to that of first order derivative.

1. Which of the following derivatives produce a double response at step changes in gray level?  
   a) First order derivative  
   b) Third order derivative  
   c) Second order derivative  
   d) First and second order derivatives  
   answer: c  
   Explanation: Second order derivatives produce a double line response for the step changes in the gray level. We also note of second-order derivatives that, for similar changes in gray-level values in an image, their response is stronger to a line than to a step, and to a point than to a line.

1. The objective of sharpening spatial filters is/are to ------  
   a) Highlight fine detail in an image  
   b) Enhance detail that has been blurred because of some error  
   c) Enhance detail that has been blurred because of some natural effect of some method of image acquisition  
   d) All of the mentioned  
   answer: d  
   Explanation: Highlighting the fine detail in an image or Enhancing detail that has been blurred because of some error or some natural effect of some method of image acquisition, is the principal objective of sharpening spatial filters.

1. Sharpening is analogous to which of the following operations?  
   a) To spatial integration  
   b) To spatial differentiation  
   c) All of the mentioned  
   d) None of the mentioned  
   answer: b  
   Explanation: Smoothing is analogous to integration and so, sharpening to spatial differentiation.

1. What kind of relation can be obtained between first order derivative and second order derivative of an image having a on the basis of edge productions that shows a transition like a ramp of constant slope?  
   a) First order derivative produces thick edge while second order produces a very fine edge  
   b) Second order derivative produces thick edge while first order produces a very fine edge  
   c) Both first and second order produces thick edge  
   d) Both first and second order produces a very fine edge  
   answer: a  
   Explanation: the first order derivative remains nonzero along the entire ramp of constant slope, while the second order derivative remain nonzero only at onset and end of such ramps.  
   If an edge in an image shows transition like the ramp of constant slope, the first order and second order derivative values shows the production of thick and finer edge respectively.

1. What kind of relation can be obtained between first order derivative and second order derivative of an image on the response obtained by encountering an isolated noise point in the image?  
   a) First order derivative has a stronger response than a second order  
   b) Second order derivative has a stronger response than a first order  
   c) Both enhances the same and so the response is same for both first and second order derivative  
   d) None of the mentioned  
   answer: b  
   Explanation: This is because a second order derivative is more aggressive toward enhancing sharp changes than a first order.

1. How can Sharpening be achieved?  
   a) Pixel averaging  
   b) Slicing  
   c) Correlation  
   d) None of the mentioned  
   answer: d  
   Explanation: Sharpening is achieved using Spatial Differentiation.

1. What does Image Differentiation enhance?  
   a) Edges  
   b) Pixel Density  
   c) Contours  
   d) None of the mentioned  
   answer: a  
   Explanation: Image Differentiation enhances Edges and other discontinuities.

1. What is the Second Derivative of Image Sharpening called?  
   a) Gaussian  
   b) Laplacian  
   c) Canny  
   d) None of the mentioned  
   answer: b  
   Explanation: It is also called Laplacian.

1. For a function f(x,y), the gradient of ‘f’ at coordinates (x,y) is defined as a ------  
   a) 3-D row vector  
   b) 3-D column vector  
   c) 2-D row vector  
   d) 2-D column vector  
   answer: d  
   Explanation: The gradient is a 2-D column vector.

1. Which of the following occurs in Unsharp Masking?  
   a) Blurring original image  
   b) Adding a mask to original image  
   c) Subtracting blurred image from original  
   d) All of the mentioned  
   answer: d  
   Explanation: In Unsharp Masking, all of the above occurs in the order: Blurring, Subtracting the blurred image and then Adding the mask.

1. Which of the following is a second-order derivative operator?  
   a) Histogram  
   b) Laplacian  
   c) Gaussian  
   d) None of the mentioned  
   answer: b  
   Explanation: Laplacian is a second-order derivative operator.

1. Response of the gradient to noise and fine detail is --------- the Laplacian’s.  
   a) equal to  
   b) lower than  
   c) greater than  
   d) has no relation with  
   answer: b  
   Explanation: Response of the gradient to noise and fine detail is lower than the Laplacian’s and can further be lowered by smoothing.

1. Which of the following fails to work on dark intensity distributions?  
   a) Laplacian Transform  
   b) Gaussian Transform  
   c) Histogram Equalization  
   d) Power-law Transformation  
   answer: c  
   Explanation: Histogram Equalization fails to work on dark intensity distributions.

1. An alternate approach to median filtering is ---------  
   a) Use a mask  
   b) Gaussian filter  
   c) Sharpening  
   d) Laplacian filter  
   Answer:a  
   Explanation: Using a mask, formed from the smoothed version of the gradient image, can be used for median filtering.

1. What is accepting or rejecting certain frequency components called as?  
   a) Filtering  
   b) Eliminating  
   c) Slicing  
   d) None of the Mentioned  
   answer: a  
   Explanation: Filtering is the process of accepting or rejecting certain frequency components.

1. A filter that passes low frequencies is ---------  
   a) Band pass filter  
   b) High pass filter  
   c) Low pass filter  
   d) None of the Mentioned  
   answer: c  
   Explanation: Low pass filter passes low frequencies.

1. What is required to generate an M X N linear spatial filter?  
   a) MN mask coefficients  
   b) M+N coordinates  
   c) MN spatial coefficients  
   d) None of the Mentioned  
   answer: a  
   Explanation: To generate an M X N linear spatial filter MN mask coefficients must be specified.

1. An example of a continuous function of two variables is ---------  
   b) Intensity function  
   c) Contrast stretching  
   d) Gaussian function  
   answer: d  
   Explanation: Gaussian function has two variables and is an exponential continuous function

1. The histogram of a digital image with gray levels in the range [0, L-1] is represented by a discrete function:  
   a) h(r_k)=n_k  
   b) h(r_k )=n/n_k  
   c) p(r_k )=n_k  
   d) h(r_k )=n_k/n  
   answer: a  
   Explanation: The histogram of a digital image with gray levels in the range [0, L-1] is a discrete function h(rk )=nk, where rk is the kth gray level and nkis the number of pixels in the image having gray level rk.

1. How is the expression represented for the normalized histogram?  
   a) p(r_k )=n_k  
   b) p(r_k )=n_k/n  
   c) p(r_k)=nn_k  
   d) p(r_k )=n/n_k  
   answer: b  
   Explanation: It is common practice to normalize a histogram by dividing each of its values by the total number of pixels in the image, denoted by n. Thus, a normalized histogram is given by p(rk )=nk/n, for k=0,1,2…..L-1. Loosely speaking, p(rk ) gives an estimate of the probability of occurrence of gray-level rk. Note that the sum of all components of a normalized histogram is equal to 1.

1. Which of the following conditions does the T(r) must satisfy?  
   a) T(r) is double-valued and monotonically decreasing in the interval 0≤r≤1; and  
   0≤T(r)≤1 for 0≤r≤1  
   b) T(r) is double-valued and monotonically increasing in the interval 0≤r≤1; and  
   0≤T(r)≤1 for 0≤r≤1  
   c) T(r) is single-valued and monotonically decreasing in the interval 0≤r≤1; and  
   0≤T(r)≤1 for 0≤r≤1  
   d) T(r) is single-valued and monotonically increasing in the interval 0≤r≤1; and  
   0≤T(r)≤1 for 0≤r≤1  
   answer: d  
   Explanation: For any r satisfying the aforementioned conditions, we focus attention on transformations of the form  
   s=T(r) For 0≤r≤1  
   That produces a level s for every pixel value r in the original image.  
   For reasons that will become obvious shortly, we assume that the transformation function T(r) satisfies the following conditions:  
   T(r) is single-valued and monotonically increasing in the interval 0≤r≤1; and  
   0≤T(r)≤1 for 0≤r≤1.

1. The inverse transformation from s back to r is denoted as:  
   a) s=T-1(r) for 0≤s≤1  
   b) r=T-1(s) for 0≤r≤1  
   c) r=T-1(s) for 0≤s≤1  
   d) r=T-1(s) for 0≥s≥1  
   answer: c  
   Explanation: The inverse transformation from s back to r is denoted by:  
   r=T-1(s) for 0≤s≤1.

1. Histogram equalization or Histogram linearization is represented by of the following equation:  
   a) sk =∑k j =1 nj/n k=0,1,2,……,L-1  
   b) sk =∑k j =0 nj/n k=0,1,2,……,L-1  
   c) sk =∑k j =0 n/nj k=0,1,2,……,L-1  
   d) sk =∑k j =n nj/n k=0,1,2,……,L-1  
   answer: b  
   Explanation: A plot of pk\_ (rk) versus r_k is called a histogram .The transformation (mapping) given in sk =∑k j =0)k nj/n k=0,1,2,……,L-1 is called histogram equalization or histogram linearization.

1. Histograms are the basis for numerous spatial domain processing techniques.  
   a) True  
   b) False  
   answer: a  
   Explanation: Histograms are the basis for numerous spatial domain processing techniques. Histogram manipulation can be used effectively for image enhancement.

1. In a dark image, the components of histogram are concentrated on which side of the grey scale?  
   a) High  
   b) Medium  
   c) Low  
   d) Evenly distributed  
   answer: c  
   Explanation: We know that in the dark image, the components of histogram are concentrated mostly on the low i.e., dark side of the grey scale. Similarly, the components of histogram of the bright image are biased towards the high side of the grey scale.

1. What is the basis for numerous spatial domain processing techniques?  
   a) Transformations  
   b) Scaling  
   c) Histogram  
   d) None of the Mentioned  
   answer: c  
   Explanation: Histogram is the basis for numerous spatial domain processing techniques.

1. What is Histogram Equalisation also called as?  
   a) Histogram Matching  
   b) Image Enhancement  
   c) Histogram linearisation  
   d) None of the Mentioned  
   Answer: c  
   Explanation: Histogram Linearisation is also known as Histogram Equalisation.

1. Histogram Equalisation is mainly used for **\*\***\_\_**\*\***  
   a) Image enhancement  
   b) Blurring  
   c) Contrast adjustment  
   d) None of the Mentioned  
   Answer: a  
   Explanation: It is mainly used for Enhancement of usually dark images.

1. The output of a smoothing, linear spatial filtering is a \***\*\_\_\*\*** of the pixels contained in the neighbourhood of the filter mask.  
   a) Sum  
   b) Product  
   c) Average  
   d) Dot Product  
   Answer: c  
   Explanation: Smoothing is simply the average of the pixels contained in the neighbourhood.

1. Averaging filters is also known as \***\*\_\_\*\*** filter.  
   a) Low pass  
   b) High pass  
   c) Band pass  
   d) None of the Mentioned  
   Answer: a  
   Explanation: Averaging filters is also known as Low pass filters.

1. What is the undesirable side effects of Averaging filters?  
   a) No side effects  
   b) Blurred image  
   c) Blurred edges  
   d) Loss of sharp transitions  
   Answer: c  
   Explanation: Blue edges is the undesirable side effect of Averaging filters.

1. Which term is used to indicate that pixels are multiplied by different coefficients?  
   a) Weighted average  
   b) Squared average  
   c) Spatial average  
   d) None of the Mentioned  
   Answer: a  
   Explanation: It is called weighted average since more importance(weight) is given to some pixels.

1. Impulse noise in Order-statistic filter is also called as **\*\***\_**\*\***  
   a) Median noise  
   b) Bilinear noise  
   c) Salt and pepper noise  
   d) None of the Mentioned  
   Answer: c  
   Explanation: It is called salt-and-pepper noise because of its appearance as white and black dots superimposed on an image.

1. Best example for a Order-statistic filter is **\*\*\*\***\_\_**\*\*\*\***  
   a) Impulse filter  
   b) Averaging filter  
   c) Median filter  
   d) None of the Mentioned  
   Answer: c  
   Explanation: Median filter is the best known Order-statistic filter.

1. Which of the following is best suited for salt-and-pepper noise elimination?  
   a) Average filter  
   b) Box filter  
   c) Max filter  
   d) Median filter  
   Answer: d  
   Explanation: Median filter is better suited than average filter for salt-and-pepper noise elimination.

1. Smoothing filter is used for which of the following work(s)?  
   a) Blurring  
   b) Noise reduction  
   c) All of the mentioned  
   d) None of the mentioned  
   Answer: c  
   Explanation: Smoothing filter is used for blurring and noise reduction.

1. Which of the following filter(s) results in a value as average of pixels in the neighborhood of filter mask.  
   a) Smoothing linear spatial filter  
   b) Averaging filter  
   c) Lowpass filter  
   d) All of the mentioned  
   Answer: d  
   Explanation: The output as an average of pixels in the neighborhood of filter mask is simply the output of the smoothing linear spatial filter also known as averaging filter and lowpass filter.

1. What is/are the resultant image of a smoothing filter?  
   a) Image with high sharp transitions in gray levels  
   b) Image with reduced sharp transitions in gray levels  
   c) All of the mentioned  
   d) None of the mentioned  
   Answer: b  
   Explanation: Random noise has sharp transitions in gray levels and smoothing filters does noise reduction.

1. At which of the following scenarios averaging filters is/are used?  
   a) In the reduction of irrelevant details in an image  
   b) For smoothing of false contours  
   c) For noise reductions  
   d) All of the mentioned  
   Answer: d  
   Explanation: Averaging filter or smoothing linear spatial filter is used: for noise reduction by reducing the sharp transitions in gray level, for smoothing false contours that arises because of use of insufficient number of gray values and for reduction of irrelevant data i.e. the pixels regions that are small in comparison of filter mask

1. Is it true or false that “the original pixel value is included while computing the median using gray-levels in the neighborhood of the original pixel in median filter case”?  
   a) True  
   b) False  
   Answer: a  
   Explanation: A median filter the pixel value is replaced by median of the gray-level in the neighborhood of that pixel and also the original pixel value is included while computing the median.

1. Two filters of similar size are used for smoothing image having impulse noise. One is median filter while the other is a linear spatial filter. Which would the blurring effect of both?  
   a) Median filter effects in considerably less blurring than the linear spatial filters  
   b) Median filter effects in considerably more blurring than the linear spatial filters  
   c) Both have the same blurring effect  
   d) All of the mentioned  
   Answer: a  
   Explanation: For impulse noise, median filter is much effective for noise reduction and causes considerably less blurring than the linear spatial filters.

1. An image contains noise having appearance as black and white dots superimposed on the image. Which of the following noise(s) has the same appearance?  
   a) Salt-and-pepper noise  
   b) Gaussian noise  
   c) All of the mentioned  
   d) None of the mentioned  
   Answer: c  
   Explanation: An impulse noise has an appearance as black and white dots superimposed on the image. This is also known as Salt-and-pepper noise.

1. While performing the median filtering, suppose a 3\*3 neighborhood has value (10, 20, 20, 20, 15, 20, 20, 25, 100), then what is the median value to be given to the pixel under filter?  
   a) 15  
   b) 20  
   c) 100  
   d) 25  
   Answer: b  
   Explanation: The values are first sorted and so turns out to (10, 15, 20, 20, 20, 20, 20, 25, and 100). For a 3\*3 neighborhood the 5th largest value is the median, and so is 20.

1. Which of the following fact(s) is/are true for the relationship between low frequency component of Fourier transform and the rate of change of gray levels?  
   a) Moving away from the origin of transform the low frequency corresponds to smooth gray level variation  
   b) Moving away from the origin of transform the low frequencies corresponds to abrupt change in gray level  
   c) All of the mentioned  
   d) None of the mentioned  
   Answer: c  
   Explanation: Moving away from the origin of transform the low frequency corresponds to the slowly varying components in an image. Moving further away from origin the higher frequencies corresponds to faster gray level changes.

1. Which of the following fact(s) is/are true for the relationship between high frequency component of Fourier transform and the rate of change of gray levels?  
   a) Moving away from the origin of transform the high frequency corresponds to smooth gray level variation  
   b) Moving away from the origin of transform the higher frequencies corresponds to abrupt change in gray level  
   c) All of the mentioned  
   d) None of the mentioned  
   Answer: b  
   Explanation: Moving away from the origin of transform the low frequency corresponds to the slowly varying components in an image. Moving further away from origin the higher frequencies corresponds to faster gray level changes.

1. To set the average value of an image zero, which of the following term would be set 0 in the frequency domain and the inverse transformation is done, where F(u, v) is Fourier transformed function of f(x, y)?  
   a) F(0, 0)  
   b) F(0, 1.
   c) F(1, 0)  
   d) None of the mentioned  
   Answer: a  
   Explanation: For an image f(x, y), the Fourier transform at origin of an image, F(0, 0), is equal to the average value of the image.

1. Which of the following filter(s) attenuates high frequency while passing low frequencies of an image?  
   a) Unsharp mask filter  
   b) Lowpass filter  
   c) Zero-phase-shift filter  
   d) All of the mentioned  
   Answer: b  
   Explanation: A lowpass filter attenuates high frequency while passing low frequencies.

1. Which of the following filter(s) attenuates low frequency while passing high frequencies of an image?  
   a) Unsharp mask filter  
   b) Highpass filter  
   c) Zero-phase-shift filter  
   d) All of the mentioned  
   Answer: b  
   Explanation: A highpass filter attenuates low frequency while passing high frequencies.

1. Which of the following filter have a less sharp detail than the original image because of attenuation of high frequencies?  
   a) Highpass filter  
   b) Lowpass filter  
   c) Zero-phase-shift filter  
   d) None of the mentioned  
   Answer: b  
   Explanation: A lowpass filter attenuates high so the image has less sharp details.

1. The feature(s) of a highpass filtered image is/are \***\*\_\*\***  
   a) Have less gray-level variation in smooth areas  
   b) Emphasized transitional gray-level details  
   c) An overall sharper image  
   d) All of the mentioned  
   Answer: d  
   Explanation: A highpass filter attenuates low frequency so have less gray-level variation in smooth areas, and allows high frequencies so have emphasized transitional gray-level details, resulting in a sharper image.

1. A spatial domain filter of the corresponding filter in frequency domain can be obtained by applying which of the following operation(s) on filter in frequency domain?  
   a) Fourier transform  
   b) Inverse Fourier transform  
   c) None of the mentioned  
   d) All of the mentioned  
   Answer: b  
   Explanation: Filters in spatial domain and frequency domain has a Fourier transform pair relation. A spatial domain filter of the corresponding filter in frequency domain can be obtained by applying inverse Fourier transform on frequency domain filter.

1. A frequency domain filter of the corresponding filter in spatial domain can be obtained by applying which of the following operation(s) on filter in spatial domain?  
   a) Fourier transform  
   b) Inverse Fourier transform  
   c) None of the mentioned  
   d) All of the mentioned  
   Answer: a  
   Explanation: Filters in spatial domain and frequency domain has a Fourier transform pair relation. A frequency domain filter of the corresponding filter in spatial domain can be obtained by applying inverse Fourier transform on spatial domain filter.

1. Which of the following filtering is done in frequency domain in correspondence to lowpass filtering in spatial domain?  
   a) Gaussian filtering  
   b) Unsharp mask filtering  
   c) High-boost filtering  
   d) None of the mentioned  
   Answer: a  
   Explanation: A plot of Gaussian filter in frequency domain can be recognized similar to lowpass filter in spatial domain.

1. Smoothing in frequency domain is achieved by attenuating which of the following component in the transform of a given image?  
   a) Attenuating a range of high-frequency components  
   b) Attenuating a range of low-frequency components  
   c) All of the mentioned  
   d) None of the mentioned  
   Answer: a  
   Explanation: Since, edges and sharp transitions contribute significantly to high-frequency contents in the gray level of an image. So, smoothing is done by attenuating a range of high-frequency components.

1. Which of the following is/are considered as type(s) of lowpass filters?  
   a) Ideal  
   b) Butterworth  
   c) Gaussian  
   d) All of the mentioned  
   Answer: d  
   Explanation: Lowpass filters are considered of three types: Ideal, Butterworth, and Gaussian.

1. Which of the following lowpass filters is/are covers the range of very sharp filter function?  
   a) Ideal lowpass filters  
   b) Butterworth lowpass filter  
   c) Gaussian lowpass filter  
   d) All of the mentioned  
   Answer: a  
   Explanation: Ideal lowpass filter covers the range of very sharp filter functioning of lowpass filters.

1. In a filter, all the frequencies inside a circle of radius D0 are not attenuated while all frequencies outside circle are completely attenuated. The D0 is the specified nonnegative distance from origin of the Fourier transform. Which of the following filter(s) characterizes the same?  
   a) Ideal filter  
   b) Butterworth filter  
   c) Gaussian filter  
   d) All of the mentioned  
   Answer: a  
   Explanation: In ideal filter all the frequencies inside a circle of radius D0 are not attenuated while all frequencies outside the circle are completely attenuated.

1. The characteristics of the lowpass filter h(x, y) is/are\***\*\_\*\***  
   a) Has a dominant component at origin  
   b) Has a concentric, circular components about the center component  
   c) All of the mentioned  
   d) None of the mentioned  
   Answer: c  
   Explanation: the lowpass filter has two different characteristics: one is a dominant component at origin and other one is a concentric, circular components about the center component.

1. Which of the following defines the expression for BLPF H(u, v) of order n, where D(u, v) is the distance from point (u, v), D0 is the distance defining cutoff frequency?  
   a) ![img](https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-frequencydomain-filters-smoothing-q12@2x.png)  
   b) ![img](https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-frequencydomain-filters-smoothing-q12a@2x.png)  
   c) All of the mentioned  
   d) None of the mentioned  
   Answer: a  
   Explanation: BLPF is the Butterworth lowpass filter and is defined as:

1. Which of the following defines the expression for ILPF H(u, v) of order n, where D(u, v) is the distance from point (u, v), D0 is the distance defining cutoff frequency?  
   a) ![img](https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-frequencydomain-filters-smoothing-q12@2x.png)  
   b) ![img](https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-frequencydomain-filters-smoothing-q12a@2x.png)  
   c) All of the mentioned  
   d) None of the mentioned  
   Answer: a  
   Explanation: ILPF is the Ideal lowpass filter and is defined as:  
   .

1. State the statement true or false: “BLPF has sharp discontinuity and ILPF doesn’t, and so ILPF establishes a clear cutoff b/w passed and filtered frequencies”.  
   a) True  
   b) False  
   Answer: b  
   Explanation: ILPF has sharp discontinuity and BLPF doesn’t, so BLPF establishes a clear cutoff b/w passed and filtered frequencies.

1. In frequency domain terminology, which of the following is defined as “obtaining a highpass filtered image by subtracting from the given image a lowpass filtered version of itself”?  
   a) Emphasis filtering  
   b) Unsharp masking  
   c) Butterworth filtering  
   d) None of the mentioned  
   Answer: b  
   Explanation: In frequency domain terminology unsharp masking is defined as “obtaining a highpass filtered image by subtracting from the given image a lowpass filtered version of itself”.

1. Which of the following is/ are a generalized form of unsharp masking?  
   a) Lowpass filtering  
   b) High-boost filtering  
   c) Emphasis filtering  
   d) All of the mentioned  
   Answer: b  
   Explanation: Unsharp masking is defined as “obtaining a highpass filtered image by subtracting from the given image a lowpass filtered version of itself” while high-boost filtering generalizes it by multiplying the input image by a constant, say A≥1.

1. Which of the following fact is true for a image?  
   a) An image is the addition of illumination and reflectance component  
   b) An image is the subtraction of illumination component from reflectance component  
   c) An image is the subtraction of reflectance component from illumination component  
   d) An image is the multiplication of illumination and reflectance component  
   Answer: d  
   Explanation: An image is expressed as the multiplication of illumination and reflectance component.

1. If an image is expressed as the multiplication of illumination and reflectance component i.e. f(x, y)= i(x, y) r(x, y), then Validate the statement “We can directly use the equation f(x, y)= i(x, y) r(x, y) to operate separately on the frequency component of illumination and reflectance” .  
   a) True  
   b) False  
   Answer: b  
   Explanation: For an image is expressed as the multiplication of illumination and reflectance component i.e. f(x, y)= i(x, y) \* r(x, y), the equation can’t be used directly to operate separately on the frequency component of illumination and reflectance because the Fourier transform of the product of two function is not separable.

1. In Homomorphic filtering which of the following operations is used to convert input image to discrete Fourier transformed function?  
   a) Logarithmic operation  
   b) Exponential operation  
   c) Negative transformation  
   d) None of the mentioned  
   Answer: a  
   Explanation: For an image is expressed as the multiplication of illumination and reflectance component i.e. f(x, y) = i(x, y) \* r(x, y), the equation can’t be used directly to operate separately on the frequency component of illumination and reflectance because the Fourier transform of the product of two function is not separable. So, the logarithmic operation is used.I{z(x,y)}=I{ln⁡(f(x,y)) }=I{ln⁡(i(x,y)) }+I{ln⁡(r(x,y))}.

1. A class of system that achieves the separation of illumination and reflectance component of an image is termed as **\_\_\_\_**  
   a) Base class system  
   b) Homomorphic system  
   c) Base separation system  
   d) All of the mentioned  
   Answer: b  
   Explanation: Homomorphic system is a class of system that achieves the separation of illumination and reflectance component of an image.

1. The edges and other abrupt changes in gray-level of an image are associated with\***\*\_\*\***  
   a) High frequency components  
   b) Low frequency components  
   c) Edges with high frequency and other abrupt changes in gray-level with low frequency components  
   d) Edges with low frequency and other abrupt changes in gray-level with high frequency components  
   Answer: a  
   Explanation: High frequency components are related with the edges and other abrupt changes in gray-level of an image.

1. The Image sharpening in frequency domain can be achieved by which of the following method(s)?  
   a) Attenuating the high frequency components  
   b) Attenuating the low-frequency components  
   c) All of the mentioned  
   d) None of the mentioned  
   Answer: b  
   Explanation: The Image sharpening in frequency domain is achieved by attenuating the low-frequency components without disturbing the high-frequency components.

1. If D0 is the cutoff distance measured from origin of frequency rectangle and D(u, v) is the distance from point(u, v). Then what value does an Ideal Highpass filter will give if D(u, v) ≤ D0 andifD(u, v) >D0?  
   a) 0 and 1 respectively  
   b) 1 and 0 respectively  
   c) 1 in both case  
   d) 0 in both case  
   Answer: a  
   Explanation: Unlike Ideal lowpass filter, an Ideal highpass filter attenuates the low-frequency components and so gives 0 for D(u, v) ≤ D0 and 1 for D(u, v) >D0.

1. The domain that refers to image plane itself and the domain that refers to Fourier transform of an image is/are :  
   a) Spatial domain in both  
   b) Frequency domain in both  
   c) Spatial domain and Frequency domain respectively  
   d) Frequency domain and Spatial domain respectively  
   Answer: c  
   Explanation: Spatial domain itself refers to the image plane, and approaches in this category are based on direct manipulation of pixels in an image.  
   Techniques based on Frequency domain processing are based on modifying the Fourier transform of an image.

1. What is the technique for a gray-level transformation function called, if the transformation would be to produce an image of higher contrast than the original by darkening the levels below some gray-level m and brightening the levels above m in the original image.  
   a) Contouring  
   b) Contrast stretching  
   c) Mask processing  
   d) Point processing  
   Answer: b  
   Explanation: For a gray-level transformation function “s=T(r)”, where r and s are the gray-level of f(x, y) (input image) and g(x, y) (output image) respectively at any point (x, y).  
   Then the technique, contrast stretching compresses the value of r below m by transformation function into a narrow range of s, towards black and brightens the value of r above m.

1. What is the sum of all components of a normalized histogram?  
   a) 1  
   b) -1  
   c) 0  
   d) None of the mentioned

   Answer: a  
   Explanation: A normalized histogram. p(rk) = nk / n  
   Where, n is total number of pixels in image, rk the kth gray level and nk total pixels with gray level rk.  
   Here, p(rk) gives the probability of occurrence of rk.

1. Continuous functions are sampled to form a

   a)Fourier series  
   b)Fourier transform  
   c)fast Fourier series  
   **d)digital image**

1. Fourier transform of unit impulse at origin is

   a)undefined  
   b)infinity  
   **c)1**  
   d)0

1. Color transformation is processed between the

   **a)single color model**  
   b)dual color model  
   c)tri color model  
   d)any color model

1. Smoothness reduced bricks of

   pixels  
   constant intensities  
   point pixels  
   **d)edges**

1. Second derivative approximation says that it is nonzero only at

   a)ramp  
   b)step  
   **c)onset**  
   d)edges

1. Black color in image processing is usually represented by the

   **a)0**  
   b)1  
   c)255  
   d)256

1. Method in which images are input and attributes are output is called

   a)low level processes  
   b)high level processes  
   **c)mid level processes**  
   d)edge level processes

1. Common example of 2D interpolation is image

   a)enhancement  
   b)sharpening  
   c)blurring  
   **d)resizing**

1. CRT technology stands for

   a)carbon ray tube  
   **b)cathode ray tube**  
   c)cathode ray technology  
   d)carbon ray technology

1. If pixels are reconstructed without error mapping is said to be

   **a)reversible**  
   b)irreversible  
   c)temporal  
   d)facsimile

1. The principle energy source for images

   a)electrical spectrum  
   b)magnetic spectrum  
   c)electro spectrum  
   **d)electro magnetic spectrum**

1. DSP stands for

   **a)Digital signal processing**  
   b)Design signal processing  
   c)Digital signal processed  
   d)Design signal processed

1. Full color images have at least

   a)2 components  
   **b)3 components**  
   c)4 components  
   d)5 components

1. Computation of derivatives in segmentation is also called

   **a)spatial filtering**  
   b)frequency filtering  
   c)low pass filtering  
   d)high pass filtering

1. For HSI color space, no of transformations will be

   a)n = 2  
   **b)n = 3**  
   c)n = 4  
   d)n = 5

1. Filter that performs opposite to band rejected filter is called

   a)lowpass filter  
   **b)bandpass filter**  
   c)highpass filter  
   d)max filter

1. 2D Fourier transform and its inverse are infinitely

   a)aperiodic  
   **b)periodic**  
   c)linear  
   d)non linear

1. A filter is applied to an image whose response is independent of the direction of discontinuities in the image. The filter is/are **\_\_\_\_**

   a) Isotropic filters  
   b) Box filters  
   c) Median filter  
   d) All of the mentioned

   Answer: a  
   Explanation: Isotropic filter are rotation invariant because it has a same response when applied to the image first and the after rotating the image.

1. In isotropic filtering, which of the following is/are the simplest isotropic derivative operator?

   a) Laplacian  
   b) Gradient  
   c) All of the mentioned  
   d) None of the mentioned

   Answer: a  
   Explanation: An isotropic filtering is an example of second order derivative for enhancement and uses Laplacian as the simplest derivative operator, while gradient is used with first derivatives.

1. The Laplacian is which of the following operator?

   a) Nonlinear operator  
   b) Order-Statistic operator  
   c) Linear operator  
   d) None of the mentioned

   Answer: c  
   Explanation: Derivative of any order are linear operations and since, Laplacian is the simplest isotropic derivative operator, so is a linear operator.  
   Order-Statistics operator are nonlinear operators.

1. A Laplacian for an image f(x, y) is defined as:digital-image-processing-questions-answers-second-order-derivative-enhancement-q5is given by **\_\_\_\_**

   a) [f(x + 1, y) + f(x – 1, y) – 2f(x, y)] and [f(x, y + 1) + f(x, y – 1) – 2f(x, y)] respectively  
   b) [f(x + 1, y + 1) + f(x, y – 1) – 2f(x, y)] and [f(x , y + 1) + f(x – 1, y) – 2f(x, y)] respectively  
   c) [f(x, y + 1) + f(x, y – 1) – 2f(x, y)] and [f(x + 1, y) + f(x – 1, y) – 2f(x, y)] respectively  
   d) None of the mentioned

   Answer: a  
   Explanation: For a Laplacian given by:∇2 f=digital-image-processing-questions-answers-second-order-derivative-enhancement-q4  
   Applying second order derivative in x direction (∂2 f)/∂x2 = [f(x + 1, y) + f(x – 1, y) – 2f(x, y)], and  
   Applying second order derivative in y direction (∂2 f)/∂y2 = [f(x, y + 1) + f(x, y – 1) – 2f(x, y)].

1. The Laplacian ∇2 f=[f(x + 1, y) + f(x – 1, y) + f(x, y + 1) + f(x, y – 1) – 4f(x, y)], gives an isotropic result for rotations in increment by what degree?

   a) 90o  
   b) 0o  
   c) 45o  
   d) None of the mentioned

   Answer: a  
   Explanation: The given Laplacian gives isotropic result for 90o incremental rotations.

1. The Laplacian incorporated with diagonal directions, i.e. ∇2 f=[f(x + 1, y) + f(x – 1, y) + f(x, y + 1) + f(x, y – 1) – 8f(x, y)], gives an isotropic result for rotations in increment by what degree?

   a) 90o  
   b) 0o  
   c) 45o  
   d) None of the mentioned

   Answer: a  
   Explanation: The given Laplacian since includes the diagonal direction, so, gives an isotropic result for 45o incremental rotations.

1. Applying Laplacian has which of the following result(s)?

   a) Produces image having greyish edge lines  
   b) Produces image having featureless background  
   c) All of the mentioned  
   d) None of the mentioned

   Answer: c  
   Explanation: Since, Laplacian is a derivative operator, so, highlights the gray-level discontinuities in an image and deemphasizes areas with slowly varying gray levels. Hence, produces images having greyish edge lines superimposed on featureless background.

1. Applying Laplacian produces image having featureless background which is recovered maintaining the sharpness of Laplacian operation by either adding or subtracting it from the original image depending upon the Laplacian definition used. Which of the following is true based on above statement?

   a) If definition used has a negative center coefficient, then subtraction is done  
   b) If definition used has a positive center coefficient, then subtraction is done  
   c) If definition used has a negative center coefficient, then addition is done  
   d) None of the mentioned

   Answer: a  
   Explanation: Applying Laplacian produces image having featureless background which is recovered maintaining the sharpness of Laplacian operation using original image either added if Laplacian definition used has a positive center coefficient or subtracting result from original image if has a negative center coefficient.

1. A mask of size 3\*3 is formed using Laplacian including diagonal neighbors that has central coefficient as 9. Then, what would be the central coefficient of same mask if it is made without diagonal neighbors?

   a) 5  
   b) -5  
   c) 8  
   d) -8

   Answer: a  
   Explanation: The mask formed by eliminating diagonal neighbors i.e. 4f(x, y), since each diagonal contain a -2f(x, y), the mask has 5 as its central coefficient.

1. Which of the following mask(s) is/are used to sharpen images by subtracting a blurred version of original image from the original image itself?

   a) Unsharp mask  
   b) High-boost filter  
   c) All of the mentioned  
   d) None of the mentioned

   Answer: c  
   Explanation: Unsharp mask sharpens images by subtracting a blurred version of original image from the original image itself.  
   A high-boost filter is a generalized form of unsharp mask.

1. Which of the following gives an expression for high boost filtered image fhb, if f represents an image, f blurred version of f, fs unsharp mask filtered image and A ≥ 1?

   a) fhb = (A – 1) f(x, y) + f(x, y) – f x, y)  
   b) fhb = A f(x, y) – f(x,y)  
   c) fhb = (A – 1) f(x, y) + fs(x, y)  
   d) All of the mentioned

   Answer: d  
   Explanation: A high-boost filter is a generalized form of unsharp mask and is given by:  
   fhb = A f(x, y) – f (x, y)  
   Or, fhb = (A – 1) f(x, y) + f(x, y) – f(x, y), that can be written as  
   fhb = (A – 1) f(x, y) + fs(x, y), where fs(x, y) = f(x, y) – f (x, y).

1. If we use a Laplacian to obtain sharp image for unsharp mask filtered image fs(x, y) of f(x, y) as input image, and if the center coefficient of the Laplacian mask is negative then, which of the following expression gives the high boost filtered image fhb, if ∇2 f represent Laplacian?

   a) fhb = A f(x, y) – ∇2 f(x,y)  
   b) fhb = A f(x, y) + ∇2 f(x,y)  
   c) fhb = ∇2 f(x,y)  
   d) None of the mentioned

   Answer: a  
   Explanation: If Laplacian is used to obtain sharp image for unsharp mask filtered image, then

1. Why is scaling of Laplacian filtered images necessary?  
   a) Because it contain high positive values  
   b) Because it contain high negative value  
   c) Because it contain both positive and negative values  
   d) None of the mentioned

   Answer: c  
   Explanation: A Laplacian filtered image contain both positive and negative values of comparable magnitudes. So, scaling is necessary.

1. Which of the following fact is true for the masks that includes diagonal neighbors than the masks that doesn’t?

   a) Mask that excludes diagonal neighbors has more sharpness than the masks that doesn’t  
   b) Mask that includes diagonal neighbors has more sharpness than the masks that doesn’t  
   c) Both masks have same sharpness result  
   d) None of the mentioned

   Answer: b  
   Explanation: Including diagonal neighbor pixels enhances sharpness of the image. So, Mask that includes diagonal neighbors has more sharpness than the masks that doesn’t.

1. The expression [∂2 f(x,y)/∂x2 +∂2 f(x,y)/∂y2] is considered as \***\*\_\*\*** where f(x, y) is an input image.

   a) Laplacian of f(x, y)  
   b) Gradient of f(x, y)  
   c) All of the mentioned  
   d) None of the mentioned

   Answer: a  
   Explanation: The Laplacian for an image f(x, y) is defined as: ∇2 f=∂2 f/∂x2 + ∂2 f/∂y2 .

1. Assuming that the origin of F(u, v), Fourier transformed function of f(x, y) an input image, has been correlated by performing the operation f(x, y)(-1)x+y prior to taking the transform of the image. If F and f are of same size, then what does the given operation is/are supposed to do?

   a) Resize the transform  
   b) Rotate the transform  
   c) Shifts the center transform  
   d) All of the mentioned

   Answer: c  
   Explanation: The given operation f(x, y)(-1)x+y shifts the center transform so that (u, v)=(0,0) is at point (M/2, N/2) for F and f of same size M\*N.

1. Computing the Fourier transform of the Laplacian result in spatial domain is equivalent to multiplying the F(u, v), Fourier transformed function of f(x, y) an input image, and H(u, v), the filter used for implementing Laplacian in frequency domain. This dual relationship is expressed as \***\*\_\*\***

   a) Fourier transform pair notation  
   b) Laplacian  
   c) Gradient  
   d) None of the mentioned

   Answer: a  
   Explanation: The Fourier transform of the Laplacian result in spatial domain is equivalent to multiplying the F(u, v) and H(u, v). This dual relationship is expressed as Fourier transform pair notation given by: ∇2 f(x,y)-[(u – M/2)2+ (v – N/2)2]F(u,v), for an image of size M \*N.

1. An enhanced image can be obtained as: g(x,y)=f(x,y)-∇2 f(x,y), where Laplacian is being subtracted from f(x, y) the input image. What does this conclude?

   a) That the center spike would be negative  
   b) That the immediate neighbors of center spike would be positive.  
   c) All of the mentioned  
   d) None of the mentioned

   Answer: c  
   Explanation: For the above given enhanced image the Laplacian subtraction suggest that the center coefficient of Laplacian mask is negative and so the center spike is negative with its immediate neighbors being positive.

1. An image has significant edge details. Which of the following fact(s) is/are true for the gradient image and the Laplacian image of the same?

   a) The gradient image is brighter than the Laplacian image  
   b) The gradient image is brighter than the Laplacian image  
   c) Both the gradient image and the Laplacian image has equal values  
   d) None of the mentioned

   Answer: a  
   Explanation: Because the gradient enhances prominent edges better than Laplacian, so, the Gradient image with significant edge detail has higher value than in Laplacian image.

1. What is the sum of the coefficient of the mask defined using gradient?

   a) 1  
   b) -1  
   c) 0  
   d) None of the mentioned

   Answer: c  
   Explanation: Since, first order derivative of a digital function must be zero in the areas of constant grey values. So, the mask using gradient has a sum 0, so to produce a zero result if applied on constant gray level areas.

1. Gradient is used in which of the following area(s)?

   a) To aid humans in detection of defects  
   b) As a preprocessing step for automated inspections  
   c) All of the mentioned  
   d) None of the mentioned

   Answer: c  
   Explanation: Gradient has a usage in both human analysis as well as a preprocessing step for automated inspections.

1. Gradient have some important features. Which of the following is/are some of  
   them?

   a) Enhancing small discontinuities in an otherwise flat gray field
   b) Enhancing prominent edges
   c) All of the mentioned
   d) None of the mentioned

   Answer: c
   Explanation: Since gradient are used in fist order derivative image enhancement that enhances the discontinuities except for in flat areas and produces thick edge for constant slope ramp. So, Gradient has all the mentioned features.

1. “For very large value of A, a high boost filtered image is approximately equal to the original image”. State whether the statement is true or false?

   a) True  
   b) False

   Answer: a  
   Explanation: As the value of A increases, sharpening process contribution becomes less important and so at some very large value A, the contribution becomes almost negligible and so high boost filtered image is approximately equal to the original image.

1. Subtracting Laplacian from an image is proportional to which of the following?  
   a) Unsharp masking  
    b) Box filter  
    c) Median filter  
    d) None of the mentioned

   Answer: a  
   Explanation: subtracting Laplacian from an image gives:  
   f(x,y)- ∇2 f(x,y) = f(x, y) – [f(x + 1, y) + f(x – 1, y) + f(x, y + 1) + f(x, y – 1) – 4f(x, y)] That on calculation gives 5[1.2 f(x, y) – f ̅(x, y)] ≈ 5[f(x, y) – f(x, y)] Where f(x, y) – f(x, y) is the unsharp masking definition.

1. A First derivative in image processing is implemented using which of the following given operator(s)?  
   a) Magnitude of Gradient vector  
   b) The Laplacian  
   c) All of the mentioned  
   d) None of the mentioned

   Answer: a
   Explanation: Magnitude of Gradient vector is used for implementation of first derivative in image processing, while Laplacian is for second order implementation in image processing.

1. If for an image function f(x, y), the magnitude of gradient vectordigital-image-processing-questions-bank-q4is given by: mag(∇f)=[G2x+G2y](1/2), then which of the following fact is correct?  
   a) The component of Gradient vector are linear operator and also the magnitude of the vector  
   b) The component of Gradient vector are linear operator, but the magnitude are not  
   c) The component of Gradient vector are nonlinear operator and also the magnitude of the vector  
   d) The component of Gradient vector are nonlinear operator, but the magnitude are not

   Answer: b  
   Explanation: The component of Gradient vector are linear operator because these are derivatives but the magnitude of the vector are not because of the squaring and square root operations.
