# Image Processing

1. Digitizing image intensity amplitude is called  
   a) sampling  
   **b) quantization**  
   c) framing  
   d) Both A and B

1. Compressed image can be recovered back by  
   a) image enhancement  
   **b) image decompression**  
   c) image contrast  
   d) image equalization

1. Image compression comprised of  
   a) encoder  
   b) decoder  
   c) frames  
   **d) Both A and B**

1. What would you use compression for?  
   **a) Making an image file smaller**  
   b) Modifying an image

1. Makes the file smaller by deleting parts of the file permanently (forever)  
   **a) Lossy Compression**  
   b) Lossless Compression

1. Makes the file smaller by giving repeated patterns/colors a specific code  
   a) Lossy Compression  
   **b) Lossless Compression**

1. Which file types use Lossy compression?  
   **a) JPEG, GIF**  
   b) PNG, BMP

1. Which file types use Lossless compression?  
   a) JPEG, GIF  
   **b) PNG, BMP**

1. Which of these is an advantage for Lossy compression?  
   **a) The file size becomes significantly (much) smaller**  
   b) The file size does not become much smaller than 50%

1. Error of the image is referred to as  
   A. pixels  
   B. matrix  
   C. frames  
   **D. noise**

1. Reducing the data required referred to  
   A. image enhancement  
   **B. image compression**  
   C. image contrast  
   D. image equalization

1. Digitizing the coordinate values is called  
   A. radiance  
   B. illuminance  
   **C. sampling**  
   D. quantization

1. Black and white images have only  
   **A. 2 levels**  
   B. 3 levels  
   C. 4 levels  
   D. 5 levels

1. A continuous image is digitised at **\_\_** points.  
   a) random  
   b) vertex  
   c) contour  
   d) sampling

   Answer: d  
   Explanation: The samp

1. The transition between continuous values of the image function and its digital equivalent is called **\_\_\_\_\_**  
   a) Quantisation  
   b) Sampling  
   c) Rasterisation  
   d) None of the Mentioned

   Answer: a  
   Explanation: The transition between continuous values of the image function and its digital equivalent is called Quantisation.

1. Images quantised with insufficient brightness levels will lead to the occurrence of **\_\_\_\_**  
   a) Pixillation  
   b) Blurring  
   c) False Contours  
   d) None of the Mentioned

   Answer: c  
   Explanation: This effect arises when the number brightness levels is lower that which the human eye can distinguish.

1. The smallest discernible change in intensity level is called **\_\_\_\_**  
   a) Intensity Resolution  
   b) Contour  
   c) Saturation  
   d) Contrast

   Answer: a  
   Explanation: Number of bits used to quantise intensity of an image is called intensity resolution.

1. Quantitatively, spatial resolution cannot be represented in which of the following ways  
   a) line pairs  
   b) pixels  
   c) dots  
   d) none of the Mentioned

   Answer: d  
   Explanation: All the options can be used to represent spatial resolution.

1. An image is considered to be a function of a(x,y), where a represents:  
   a) Height of image  
   b) Width of image  
   c) Amplitude of image  
   d) Resolution of image

   Answer: c  
   Explanation: The image is a collection of dots with a definite intensity or amplitude.

1. What is pixel?  
   a) Pixel is the elements of a digital image  
   b) Pixel is the elements of an analog image  
   c) Pixel is the cluster of a digital image  
   d) Pixel is the cluster of an analog image

   Answer: a  
   Explanation: An Image is a collection of individual points referred as pixel, thus a Pixel is the element of a digital image.

1. Which means the assigning meaning to a recognized object.  
   a) Interpretation  
   b) Recognition  
   c) Acquisition  
   d) Segmentation

   Answer: a  
   Explanation: The interpretation is called the assigning meaning to recognized object.

1. What is the first and foremost step in Image Processing?  
   a) Image restoration  
   b) Image enhancement  
   c) Image acquisition  
   d) Segmentation

   Answer: c  
   Explanation: Image acquisition is the first process in image processing. Note that acquisition could be as simple as being given an image that is already in digital form. Generally, the image acquisition stage involves preprocessing, such as scaling.

1. In which step of processing, the images are subdivided successively into smaller regions?  
   a) Image enhancement  
   b) Image acquisition  
   c) Segmentation  
   d) Wavelets

   Answer: d  
   Explanation: Wavelets are the foundation for representing images in various degrees of resolution. Wavelets are particularly used for image data compression and for pyramidal representation, in which images are subdivided successively into smaller regions.

1. What is the next step in image processing after compression?  
   a) Wavelets  
   b) Segmentation  
   c) Representation and description  
   d) Morphological processing

   Answer: d  
   Explanation: Steps in image processing:  
   Image acquisition-> Image enhancement-> Image restoration-> Color image processing-> Wavelets and multi resolution processing-> Compression-> Morphological processing-> Segmentation-> Representation & description-> Object recognition.

1. What is the step that is performed before color image processing in image processing?  
   a) Wavelets and multi resolution processing  
   b) Image enhancement  
   c) Image restoration  
   d) Image acquisition

   Answer: c  
   Explanation: Steps in image processing:  
   Image acquisition-> Image enhancement-> Image restoration-> Color image processing-> Wavelets and multi resolution processing-> Compression-> Morphological processing-> Segmentation-> Representation & description-> Object recognition.

1. How many number of steps are involved in image processing?  
   a) 10  
   b) 9  
   c) 11  
   d) 12

   Answer: a  
   Explanation: Steps in image processing:  
   Image acquisition-> Image enhancement-> Image restoration-> Color image processing-> Wavelets and multi resolution processing-> Compression-> Morphological processing-> Segmentation-> Representation & description-> Object recognition.

1. What is the expanded form of JPEG?  
   a) Joint Photographic Expansion Group  
   b) Joint Photographic Experts Group  
   c) Joint Photographs Expansion Group  
   d) Joint Photographic Expanded Group

   Answer: b  
   Explanation: Image compression is familiar (perhaps inadvertently) to most users of computers in the form of image file extensions, such as the jpg file extension used in the JPEG (Joint Photographic Experts Group) image compression standard.

1. Which of the following step deals with tools for extracting image components those are useful in the representation and description of shape?  
   a) Segmentation  
   b) Representation & description  
   c) Compression  
   d) Morphological processing

   Answer: d  
   Explanation: Morphological processing deals with tools for extracting image components that are useful in the representation and description of shape. The material in this chapter begins a transition from processes that output images to processes that output image attributes.

1. In which step of the processing, assigning a label (e.g., “vehicle”) to an object based on its descriptors is done?  
   a) Object recognition  
   b) Morphological processing  
   c) Segmentation  
   d) Representation & description

   Answer: a  
   Explanation: Recognition is the process that assigns a label (e.g., “vehicle”) to an object based on its descriptors. We conclude our coverage of digital image processing with the development of methods for recognition of individual objects.

1. What role does the segmentation play in image processing?  
   a) Deals with extracting attributes that result in some quantitative information of interest  
   b) Deals with techniques for reducing the storage required saving an image, or the bandwidth required transmitting it  
   c) Deals with partitioning an image into its constituent parts or objects  
   d) Deals with property in which images are subdivided successively into smaller regions

   Answer: c  
   Explanation: Segmentation procedures partition an image into its constituent parts or objects. In general, autonomous segmentation is one of the most difficult tasks in digital image processing. A rugged segmentation procedure brings the process a long way toward successful solution of imaging problems that require objects to be identified individually.

1. What is the correct sequence of steps in image processing?  
   a) Image acquisition->Image enhancement->Image restoration->Color image processing->Compression->Wavelets and multi resolution processing->Morphological processing->Segmentation->Representation & description->Object recognition  
   b) Image acquisition->Image enhancement->Image restoration->Color image processing->Wavelets and multi resolution processing->Compression->Morphological processing->Segmentation->Representation & description->Object recognition  
   c) Image acquisition->Image enhancement->Color image processing->Image restoration->Wavelets and multi resolution processing->Compression->Morphological processing->Segmentation->Representation & description->Object recognition  
   d) Image acquisition->Image enhancement->Image restoration->Color image processing->Wavelets and multi resolution processing->Compression->Morphological processing->Representation & description->Segmentation->Object recognition

   Answer: b  
   Explanation: Steps in image processing:  
   Image acquisition-> Image enhancement->Image restoration->Color image processing->Wavelets and multi resolution processing->Compression->Morphological processing->Segmentation->Representation & description->Object recognition.

1. To convert a continuous sensed data into Digital form, which of the following is required?  
   a) Sampling  
   b) Quantization  
   c) Both Sampling and Quantization  
   d) Neither Sampling nor Quantization

   Answer: c  
   Explanation: The output of the most sensor is a continuous waveform and the amplitude and spatial behavior of such waveform are related to the physical phenomenon being sensed.

1. Assume that an image f(x, y) is sampled so that the result has M rows and N columns. If the values of the coordinates at the origin are (x, y) = (0, 0), then the notation (0, 1. is used to signify :  
   a) Second sample along first row  
   b) First sample along second row  
   c) First sample along first row  
   d) Second sample along second row

   Answer: a  
   Explanation: The values of the coordinates at the origin are (x, y) = (0, 0). Then, the next coordinate values (second sample) along the first row of the image are represented as (x, y) = (0, 1..

1. The resulting image of sampling and quantization is considered a matrix of real numbers. By what name(s) the element of this matrix array is called **\_\_\_\_\_\_\_\_**  
   a) Image element or Picture element  
   b) Pixel or Pel  
   c) All of the mentioned  
   d) None of the mentioned

   Answer: c  
   Explanation: Sampling and Quantization of an image f(x, y) forms a matrix of real numbers and each element of this matrix array is commonly known as Image element or Picture element or Pixel or Pel.

1. Validate the statement “When in an Image an appreciable number of pixels exhibit high dynamic range, the image will have high contrast.”  
   a) True  
   b) False

   Answer: a  
   Explanation: In an Image if an appreciable number of pixels exhibit high dynamic range property, the image will have high contrast.

1. A continuous image is digitized at **\_\_** points.  
   a) random  
   b) vertex  
   c) contour  
   d) sampling

   Answer: d  
   Explanation: The sampling points are ordered in the plane and their relation is called a Grid.

1. The transition between continuous values of the image function and its digital equivalent is called **\_\_\_\_\_\_\_\_**  
   a) Quantization  
   b) Sampling  
   c) Rasterization  
   d) None of the Mentioned

   Answer: a  
   Explanation: The transition between continuous values of the image function and its digital equivalent is called Quantization.

1. The smallest discernible change in intensity level is called **\_\_\_\_**  
   a) Intensity Resolution  
   b) Contour  
   c) Saturation  
   d) Contrast

   Answer: a  
   Explanation: Number of bits used to quantize intensity of an image is called intensity resolution.

1. The section of the real plane spanned by the coordinates of an image is called the **\_\_\_\_\_**  
   a) Spacial Domain  
   b) Coordinate Axes  
   c) Plane of Symmetry  
   d) None of the Mentioned

   Answer: a  
   Explanation: The section of the real plane spanned by the coordinates of an image is called the Spacial Domain, with the x and y coordinates referred to as Spacial coordinates.

1. The difference between the highest and the lowest intensity levels in an image is **\_\_\_\_**  
   a) Noise  
   b) Saturation  
   c) Contrast  
   d) Brightness

   Answer: c  
   Explanation: Contrast is the measure of the difference is intensity between the highest and the lowest intensity levels in an image.

1. Image processing approaches operating directly on pixels of input image work directly in \***\*\_\_\*\***  
   a) Transform domain  
   b) Spatial domain  
   c) Inverse transformation  
   d) None of the Mentioned

   Answer: b  
   Explanation: Operations directly on pixels of input image work directly in Spatial Domain.

1. Noise reduction is obtained by blurring the image using smoothing filter.  
   a) True  
   b) False

   Answer: a  
   Explanation: Noise reduction is obtained by blurring the image using smoothing filter. Blurring is used in pre-processing steps, such as removal of small details from an image prior to object extraction and, bridging of small gaps in lines or curves.

1. What is the output of a smoothing, linear spatial filter?  
   a) Median of pixels  
   b) Maximum of pixels  
   c) Minimum of pixels  
   d) Average of pixels

   Answer: d  
   Explanation: The output or response of a smoothing, linear spatial filter is simply the average of the pixels contained in the neighbourhood of the filter mask.

1. Smoothing linear filter is also known as median filter.  
   a) True  
   b) False

   Answer: b  
   Explanation: Since the smoothing spatial filter performs the average of the pixels, it is also called as averaging filter.

1. Which of the following in an image can be removed by using smoothing filter?  
   a) Smooth transitions of gray levels  
   b) Smooth transitions of brightness levels  
   c) Sharp transitions of gray levels  
   d) Sharp transitions of brightness levels

   Answer: c  
   Explanation: Smoothing filter replaces the value of every pixel in an image by the average value of the gray levels. So, this helps in removing the sharp transitions in the gray levels between the pixels. This is done because, random noise typically consists of sharp transitions in gray levels.

1. Which of the following is the disadvantage of using smoothing filter?  
   a) Blur edges  
   b) Blur inner pixels  
   c) Remove sharp transitions  
   d) Sharp edges

   Answer: a  
   Explanation: Edges, which almost always are desirable features of an image, also are characterized by sharp transitions in gray level. So, averaging filters have an undesirable side effect that they blur these edges.

1. The mask shown in the figure below belongs to which type of filter?  
   ![img](https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-smoothing-spatial-filters-q7@2x.png)  
    a) Sharpening spatial filter  
    b) Median filter  
    c) Sharpening frequency filter  
    d) Smoothing spatial filter

   Answer: d  
    Explanation: This is a smoothing spatial filter. This mask yields a so called weighted average, which means that different pixels are multiplied with different coefficient values. This helps in giving much importance to the some pixels at the expense of others.

1. The mask shown in the figure below belongs to which type of filter?  
   ![img](https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-smoothing-spatial-filters-q8@2x.png)  
    a) Sharpening spatial filter  
    b) Median filter  
    c) Smoothing spatial filter  
    d) Sharpening frequency filter

   Answer: c  
    Explanation: The mask shown in the figure represents a 3×3 smoothing filter. Use of this filter yields the standard average of the pixels under the mask.

1. If the size of the averaging filter used to smooth the original image to first image is 9, then what would be the size of the averaging filter used in smoothing the same original picture to second in second image?  
   ![img](https://www.sanfoundry.com/wp-content/uploads/2017/06/digital-image-processing-questions-answers-smoothing-spatial-filters-q10.png)  
    a) 3  
    b) 5  
    c) 9  
    d) 15

   Answer: d  
    Explanation: We know that, as the size of the filter used in smoothening the original image that is averaging filter increases then the blurring of the image. Since the second image is more blurred than the first image, the window size should be more than 9.

1. Median filter belongs to which category of filters?  
   a) Linear spatial filter  
   b) Frequency domain filter  
   c) Order static filter  
   d) Sharpening filter

   Answer: c  
   Explanation: The median filter belongs to order static filters, which, as the name implies, replaces the value of the pixel by the median of the gray levels that are present in the neighbourhood of the pixels.

1. Median filters are effective in the presence of impulse noise.  
   a) True  
   b) False

   Answer: a  
   Explanation: Median filters are used to remove impulse noises, also called as salt-and-pepper noise because of its appearance as white and black dots in the image.

1. In Homomorphic filtering which of the following operations is used to convert input image to discrete Fourier transformed function?  
   a) Logarithmic operation  
   b) Exponential operation  
   c) Negative transformation  
   d) None of the mentioned

   Answer: a  
   Explanation: For an image is expressed as the multiplication of illumination and reflectance component i.e. f(x, y) = i(x, y) \* r(x, y), the equation can’t be used directly to operate separately on the frequency component of illumination and reflectance because the Fourier transform of the product of two function is not separable. So, the logarithmic operation is used.I{z(x,y)}=I{ln⁡(f(x,y)) }=I{ln⁡(i(x,y)) }+I{ln⁡(r(x,y))}.

1. **Convolution in Spatial Domain** Is _Multiplication_ in **Frequency Domain**.

1. Sudden changes in intensity produces peak in  
   a) **first derivative**  
   b) second derivative  
   c) third derivative  
   d) Both A and B

1. Gaussian noise is referred to as  
   a) red noise  
   b) black noise  
   c) white noise  
   d) **normal noise**

1. Digitizing image intensity amplitude is called  
   a) sampling  
   b) **quantization**  
   c) framing  
   d) Both A and B

1. For line detection we use mask that is  
   a) Gaussian  
   b) **laplacian**  
   c) ideal  
   d) butterworth

1. Gradient computation equation is  
   a) **\|Gx\| + \|Gy\|**  
   b) \|Gx\| - \|Gy\|  
   c) \|Gx\| / \|Gy\|  
   d) \|Gx\| x \|Gy\|

1. For finding horizontal lines we use mask of values  
   a) **[-1 -1 -1;
   2 2 2;
   -1 -1 -1]**  
   b) [2 -1 -1;
   -1 2 -1;
   -1 -1 2]  
   c) [-1 2 -1;
   -1 2 -1;
   -1 2 -1]  
   d) [-1 -1 2;
   -1 2 -1;
   2 -1 -1]

1. To avoid negative values taking absolute values in lapacian image doubles **thickness of lines**.

1. Horizontal gradient pixels are denoted by **Gx**

1. Filter that replaces pixel value with medians of intensity levels is **median filter**

1. For finding lines at angle 45 we use mask of values  
   a) [-1 -1 -1; 2 2 2; -1 -1 -1]  
   b) **[2 -1 -1; -1 2 -1; -1 -1 2]**  
   c) [-1 2 -1; -1 2 -1; -1 2 -1]  
   d) [-1 -1 2; -1 2 -1;2 -1 -1]

1. Second derivative approximation says that values along ramp must be  
   a) nonzero  
   b) **zero**  
   c) positive  
   d) negative

1. High pass filters promotes  
   a) low intensity components  
   b) mid intensity components  
   c) **high intensity components**  
   d) all components

1. Gradient magnitude images are more useful in  
   a) point detection  
   b) line detection  
   c) area detection  
   d) **edge detection**

1. Image having gradient pixels is called **gradient image**

1. Digital images are displayed as a discrete set if  
   a) values  
   b) numbers  
   c) frequencies  
   d) **intensities**

1. ----- filter cannot be implemented using convolution mechanism  
   a) average  
   b) **gausian**  
   c) median  
   d) disk

1. To remove salt-and-pepper noise witout blurring we use  
   a) max filter  
   b) **median filter**  
   c) min filter  
   d) smoothing filter

1. Sharpening the images is commonly accomplished by performing a spatial ------- of the image field.  
   a) Min Filter  
   b) Smoothing Filter  
   c) Integration  
   d) **Differentiation**

1. One of the following filters is nonlinear  
   a) Gaussian Filter  
   b) Averaging Filter  
   c) Laplacian Filter  
   d) **Median**

1. the sum of all elements inthe mask of the smoothing averaging spatial filtering must be equal to  
   a) m rows  
   b) n columns  
   c) n\*m  
   d) **1**

1. Edge detection in images is commonly accomplished by performing a spatial ------ of the image field  
   a) Min Filter  
   b) Smoothing Filter  
   c) Integration  
   d) **Differentiation**

1. For finding vertical lines we use mask of values  
   a) [-1 -1 -1; 2 2 2; -1 -1 -1]  
   b) [2 -1 -1; -1 2 -1; -1 -1 2]  
   c) **[-1 2 -1; -1 2 -1; -1 2 -1]**  
   d) [-1 -1 2; -1 2 -1;2 -1 -1]

1. Which of the following expression is used to denote spatial domain process?  
   a) g(x,y)=T[f(x,y)]  
   b) f(x+y)=T[g(x+y)]  
   c) g(xy)=T[f(xy)]  
   d) g(x-y)=T[f(x-y)]
   Answer: a  
   Explanation: Spatial domain processes will be denoted by the expression g(x,y)=T[f(x,y)], where f(x,y) is the input image, g(x,y) is the processed image, and T is an operator on f, defined over some neighborhood of (x, y). In addition, T can operate on a set of input images, such as performing the pixel-by-pixel sum of K images for noise reduction.
1. Which of the following is the primary objective of sharpening of an image?  
   a) Blurring the image  
   b) Highlight fine details in the image  
   c) Increase the brightness of the image  
   d) Decrease the brightness of the image
   Answer: b  
   Explanation: The sharpening of image helps in highlighting the fine details that are present in the image or to enhance the details that are blurred due to some reason like adding noise.
1. Image sharpening process is used in electronic printing.  
   a) True  
   b) False
   Answer: a  
   Explanation: The applications of image sharpening is present in various fields like electronic printing, autonomous guidance in military systems, medical imaging and industrial inspection.
1. In spatial domain, which of the following operation is done on the pixels in sharpening the image?  
   a) Integration  
   b) Average  
   c) Median  
   d) Differentiation
   Answer: d  
   Explanation: We know that, in blurring the image, we perform the average of pixels which can be considered as integration. As sharpening is the opposite process of blurring, logically we can tell that we perform differentiation on the pixels to sharpen the image.
1. Image differentiation enhances the edges, discontinuities and deemphasizes the pixels with slow varying gray levels.  
   a) True  
   b) False
   Answer: a  
   Explanation: Fundamentally, the strength of the response of the derivative operative is proportional to the degree of discontinuity in the image. So, we can state that image differentiation enhances the edges, discontinuities and deemphasizes the pixels with slow varying gray levels.
1. If f(x,y) is an image function of two variables, then the first order derivative of a one dimensional function, f(x) is:  
   a) f(x+1.-f(x)  
   b) f(x)-f(x+1.  
   c) f(x-1.-f(x+1.  
   d) f(x)+f(x-1.
   Answer: a  
   Explanation: The first order derivative of a single dimensional function f(x) is the difference between f(x) and f(x+1..  
   That is, ∂f/∂x=f(x+1.-f(x).
1. Isolated point is also called as noise point.  
   a) True  
   b) False
   Answer: a  
   Explanation: The point which has very high or very low gray level value compared to its neighbours, then that point is called as isolated point or noise point. The noise point of is of one pixel size.
1. What is the thickness of the edges produced by first order derivatives when compared to that of second order derivatives?  
   a) Finer  
   b) Equal  
   c) Thicker  
   d) Independent
   Answer: c  
   Explanation: We know that, the first order derivative is nonzero along the entire ramp while the second order is zero along the ramp. So, we can conclude that the first order derivatives produce thicker edges and the second order derivatives produce much finer edges.
1. First order derivative can enhance the fine detail in the image compared to that of second order derivative.  
   a) True  
   b) False
   Answer: b  
   Explanation: The response at and around the noise point is much stronger for the second order derivative than for the first order derivative. So, we can state that the second order derivative is better to enhance the fine details in the image including noise when compared to that of first order derivative.
1. Which of the following derivatives produce a double response at step changes in gray level?  
   a) First order derivative  
   b) Third order derivative  
   c) Second order derivative  
   d) First and second order derivatives
   Answer: c  
   Explanation: Second order derivatives produce a double line response for the step changes in the gray level. We also note of second-order derivatives that, for similar changes in gray-level values in an image, their response is stronger to a line than to a step, and to a point than to a line.
1. The objective of sharpening spatial filters is/are to \***\*\_\*\***  
   a) Highlight fine detail in an image  
   b) Enhance detail that has been blurred because of some error  
   c) Enhance detail that has been blurred because of some natural effect of some method of image acquisition  
   d) All of the mentioned
   Answer: d  
   Explanation: Highlighting the fine detail in an image or Enhancing detail that has been blurred because of some error or some natural effect of some method of image acquisition, is the principal objective of sharpening spatial filters.
1. Sharpening is analogous to which of the following operations?  
   a) To spatial integration  
   b) To spatial differentiation  
   c) All of the mentioned  
   d) None of the mentioned
   Answer: b  
   Explanation: Smoothing is analogous to integration and so, sharpening to spatial differentiation.
1. What kind of relation can be obtained between first order derivative and second order derivative of an image having a on the basis of edge productions that shows a transition like a ramp of constant slope?  
   a) First order derivative produces thick edge while second order produces a very fine edge  
   b) Second order derivative produces thick edge while first order produces a very fine edge  
   c) Both first and second order produces thick edge  
   d) Both first and second order produces a very fine edge
   Answer: a  
   Explanation: the first order derivative remains nonzero along the entire ramp of constant slope, while the second order derivative remain nonzero only at onset and end of such ramps.  
   If an edge in an image shows transition like the ramp of constant slope, the first order and second order derivative values shows the production of thick and finer edge respectively.
1. What kind of relation can be obtained between first order derivative and second order derivative of an image on the response obtained by encountering an isolated noise point in the image?  
   a) First order derivative has a stronger response than a second order  
   b) Second order derivative has a stronger response than a first order  
   c) Both enhances the same and so the response is same for both first and second order derivative  
   d) None of the mentioned
   Answer: b  
   Explanation: This is because a second order derivative is more aggressive toward enhancing sharp changes than a first order.
1. How can Sharpening be achieved?  
   a) Pixel averaging  
   b) Slicing  
   c) Correlation  
   d) None of the mentioned
   Answer: d  
   Explanation: Sharpening is achieved using Spatial Differentiation.
1. What does Image Differentiation enhance?  
   a) Edges  
   b) Pixel Density  
   c) Contours  
   d) None of the mentioned
   Answer: a  
   Explanation: Image Differentiation enhances Edges and other discontinuities.
1. What is the Second Derivative of Image Sharpening called?  
   a) Gaussian  
   b) Laplacian  
   c) Canny  
   d) None of the mentioned
   Answer: b  
   Explanation: It is also called Laplacian.
1. For a function f(x,y), the gradient of ‘f’ at coordinates (x,y) is defined as a \***\*\_\*\***  
   a) 3-D row vector  
   b) 3-D column vector  
   c) 2-D row vector  
   d) 2-D column vector
   Answer: d  
   Explanation: The gradient is a 2-D column vector.
1. Which of the following occurs in Unsharp Masking?  
   a) Blurring original image  
   b) Adding a mask to original image  
   c) Subtracting blurred image from original  
   d) All of the mentioned
   Answer: d  
   Explanation: In Unsharp Masking, all of the above occurs in the order: Blurring, Subtracting the blurred image and then Adding the mask.
1. Which of the following is a second-order derivative operator?  
   a) Histogram  
   b) Laplacian  
   c) Gaussian  
   d) None of the mentioned
   Answer: b  
   Explanation: Laplacian is a second-order derivative operator.
